{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import netCDF4 as nc\n",
    "import datetime as dt\n",
    "import geopy.distance\n",
    "import xarray as xr\n",
    "import cfgrib\n",
    "\n",
    "existing_years_era5 = [str(year) for year in range(2023, 2025)]\n",
    "\n",
    "existing_months_era5_2023 = [\n",
    "    '01', '02', '03',\n",
    "    '04', '05', '06',\n",
    "    '07', '08', '09',\n",
    "    '10', '11', '12',\n",
    "]\n",
    "\n",
    "existing_months_era5_2024 = [\n",
    "    '01', '02', '03',\n",
    "    '04'\n",
    "]\n",
    "\n",
    "#existing_months_era5 = ['01', '02'] #shorter, for debug\n",
    "\n",
    "colsorder_weather=['year',\n",
    " 'month',\n",
    " 'day',\n",
    " 'hour',\n",
    " 'mean_temp',\n",
    " 'wind_speed',\n",
    " 'wind_direction',\n",
    " 'precip'#,\n",
    " #'soiltemp',\n",
    " #'snowdepth',\n",
    " #'humidity',\n",
    " #'radiation'\n",
    " ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_param_era5(filepath, suffix, lat, long, yearfrom, yearto, paramname, hourly_flag):\n",
    "    #outdf=pd.DataFrame({'time':[], paramname:[]}).set_index('time', inplace=True)\n",
    "    outdf=[pd.DataFrame({'time':[], paramname:[]}) for i in range(len(lat))]\n",
    "    for year in range(yearfrom, yearto+1):\n",
    "        if (existing_years_era5.count(str(year))<1):\n",
    "            print ('Year '+str(year)+ ' is not downloaded')\n",
    "            exit(-1)\n",
    "        else:\n",
    "            #for month in existing_months_era5:\n",
    "            if(year == 2023) existing_months_era5 = existing_months_era5_2023\n",
    "            if(year == 2024) existing_months_era5 = existing_months_era5_2024\n",
    "            for month in existing_months_era5:\n",
    "                print ('reading '+ suffix+'_'+str(year)+'_'+month+'.grib')\n",
    "                ds = xr.load_dataset(os.path.join(filepath, suffix+'_'+str(year)+'_'+month+'.grib'), engine=\"cfgrib\", chunks={\"latitude\":500, \"longitude\":500, \"time\": -1, \"step\": -1})\n",
    "                #ds = ds.interpolate_na()\n",
    "                \n",
    "                data_name = list (ds.keys())[0]\n",
    "                # the problem is that there are cases where we have step as a dimensions and sometimes we don't\n",
    "                # let's deal with that\n",
    "                if (len(ds.dims)==4):\n",
    "                    ds =ds.stack(real_time=('time', 'step')).swap_dims({'real_time':'valid_time'})\n",
    "                else:\n",
    "                    ds =ds.swap_dims({'time':'valid_time'})\n",
    "                for count, (lati, longi) in enumerate(zip(lat,long)):    \n",
    "                    #out =ds.sel(latitude=lati, longitude=longi,method='nearest',drop=True).resample(valid_time='1D').mean(dim='valid_time').to_dataframe()\n",
    "                    if(hourly_flag):\n",
    "                        out =ds.sel(latitude=lati, longitude=longi,method='nearest',drop=True).to_dataframe()\n",
    "                    else:\n",
    "                        out =ds.sel(latitude=lati, longitude=longi,method='nearest',drop=True).resample(valid_time='1D').mean(dim='valid_time').to_dataframe()                        \n",
    "                    out.rename(columns={data_name:paramname}, inplace=True)\n",
    "                    out.drop(out.columns.difference([paramname]), axis=1, inplace=True)\n",
    "                    #out.dropna(inplace=True)\n",
    "                    out.index.names = ['time']\n",
    "                    out.reset_index(inplace=True)\n",
    "                    #out.plot()\n",
    "                    #plt.show()\n",
    "                    out['time']=pd.to_datetime(out['time'], utc = True)\n",
    "                    out.drop(out[out['time']<dt.datetime(year, int(month), 1, 0, 0, 0, tzinfo=dt.timezone.utc)].index, inplace=True)\n",
    "                    if (int(month)<12):\n",
    "                        out.drop(out[out['time']>=dt.datetime(year, int(month)+1, 1, 0, 0, 0, tzinfo=dt.timezone.utc)].index, inplace=True)\n",
    "                    if (int(month)==12):\n",
    "                        out.drop(out[out['time']>=dt.datetime(year+1, 1, 1, 0, 0, 0, tzinfo=dt.timezone.utc)].index, inplace=True)\n",
    "                    outdf[count]=pd.concat([outdf[count], out], axis=0, ignore_index=True)\n",
    "    return outdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def interpolate_data(input_df):\n",
    "    replaced=input_df.replace(-9999, np.nan) # first replace all -9999 by nan if there are\n",
    "    # check if the entire column is nan--> no point to interpolate\n",
    "    for i in replaced.columns:\n",
    "        if (replaced[i].isnull().all()):\n",
    "            # replace it back --> will be ignored\n",
    "            replaced[i]=replaced[i].replace(np.nan,-9999).astype(np.int64)\n",
    "    replaced.interpolate(method='linear', limit_direction='both', axis=0, inplace=True)\n",
    "    return replaced\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def write_weather(df_towrite, filename):\n",
    "    print(\"Writing \"+filename)\n",
    "    linesnum=len(df_towrite)\n",
    "    with open(filename, 'w',newline=None) as fd:\n",
    "        fd.write('2'+\"\\n\")#version number, means hourly\n",
    "        fd.write( str(linesnum)+\"\\n\")\n",
    "    # let us \n",
    "    df_towrite=df_towrite[colsorder_weather]\n",
    "    df_towrite.to_csv(filename, sep='\\t', index = False, header = True, mode='a+', float_format='%.3f')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def country_name_coordinate_year():\n",
    "    \n",
    "    #startyear = 1992\n",
    "    #endyear = 1992\n",
    "    \n",
    "    #JC\n",
    "    #startyear = 1989\n",
    "    #endyear = 1991\n",
    "   \n",
    "    #SN\n",
    "    #startyear = 1990\n",
    "    #endyear = 1990\n",
    "\n",
    "    #startyear = 1986\n",
    "    #endyear = 1986\n",
    "    \n",
    "    #PT\n",
    "    #startyear = 2008\n",
    "    #endyear = 2017\n",
    "    \n",
    "    #TP\n",
    "    #startyear = 2015\n",
    "    #endyear = 2019\n",
    "    \n",
    "    #Osmia calibration\n",
    "    #startyear = 1971\n",
    "    #endyear = 1971\n",
    "    \n",
    "    #Polish weather for Angelica\n",
    "    #startyear = 2007\n",
    "    #endyear = 2016\n",
    "    \n",
    "    #AHA Ecostack\n",
    "    startyear = 2009\n",
    "    endyear = 2019\n",
    "    \n",
    "    #For Ana\n",
    "    startyear = 2013\n",
    "    endyear = 2022\n",
    "\n",
    "    # Fot bats\n",
    "    startyear = 2023\n",
    "    endyear = 2024\n",
    "    \n",
    "    #latitude and longtiude, cournty code\n",
    "    xs=[10.44519, 11.38064, 9.56189, 9.85922, 11.32218, 10.04418, 10.78797, 10.10535, 10.49498, 11.54320, 12.31061, 10.54788, 11.63675, 10.74685]#[0.3561]\n",
    "    ys=[55.31168, 55.32943, 56.49385, 56.48013, 55.38351, 55.47229, 55.21177, 56.24818, 56.30509, 55.38482, 55.67096, 55.39099, 55.28202, 55.11464]#[51.8094] lat\n",
    "    ys = [55.83284474248969]\n",
    "    xs = [12.172414928897219]\n",
    "    ys = [52.949997]\n",
    "    xs = [-1.083333]\n",
    "    ys = [59.8537293426677]\n",
    "    xs = [17.646082058597607]\n",
    "    #xs = [9.32248, 9.48258, 9.4837, 10.1259]\n",
    "    #ys = [56.2145, 56.1241, 56.214, 56.1199]\n",
    "    xs = [ 16.95]\n",
    "    ys =  [48.06666667]\n",
    "    xs = [37.175278]\n",
    "    ys =   [55.846667]  \n",
    "    xs = [7.059167]\n",
    "    ys =   [46.987778]  \n",
    "    xs = [8.670574221,9.665288104,9.829562999,10.33367601,8.352057238,8.345883746,8.517440747,8.837632361,9.651027953,9.817646729,9.962842049,10.1365146,8.683438936,9.000007843,9.000007987,9.798682779,9.945350921,10.10039131,10.57181574,11.36242223,11.84072997,11.87336241,11.17566767,11.18535726,11.48617126,8.025830962,8.023522984,8.188173555,8.186250082,8.350527202,8.348988321,8.842794363,8.842439049,9.000007861,9.000007878,9.000007896,9.157221358,9.157576708,9.157934056,9.163936476,9.164330289,9.314432872,9.315143539,9.327862472,9.32865006,9.474856308,10.1365146,10.13920702,10.29882846,10.30190515]#DK ORGP21-45 and 51-75\n",
    "    ys = [57.02304572,57.38104957,57.29024045,57.46558154,56.39291277,56.75225389,56.12412594,56.48434219,56.57258591,56.75128866,56.03146262,56.47924677,55.49569362,55.13666466,55.8555196,55.85292778,55.31272821,55.22156344,55.21639701,55.29351322,55.37319033,55.82190657,54.75767469,54.93727718,54.75169254,56.48062701,56.57045574,56.48179471,56.57162741,56.48275005,56.572586,55.22642492,55.31628477,55.22652618,55.31638637,55.40624522,55.2264249,55.31628475,55.40614327,56.84369972,56.93353585,55.22612109,55.31597992,56.84337693,56.93321196,55.49518213,56.47924677,56.56907082,56.47765422,56.56747286] # DK ORGP21-45 and 51-75\n",
    "    xs = [ 7.4475]\n",
    "    ys =  [46.948056]\n",
    "    xs = [ 13.405]\n",
    "    ys =  [52.52]\n",
    "    xs = [6.814167]\n",
    "    ys =  [50.813611]\n",
    "    ys = [51.49665580646242]\n",
    "    xs = [9.933457384965974]\n",
    "    \n",
    "    ys = [41.2]\n",
    "    xs = [-1.28]\n",
    "     \n",
    "    ys = [52.623967656585634]\n",
    "    xs = [1.2372556115023972]\n",
    "\n",
    "    ys = [46.160434, 45.513611] # North Dakota/Oregon\n",
    "    xs = [-103.394162, -122.630369] \n",
    "    \n",
    "    ys = [44.935326] # Belgrade, Serbia (similar to Oregon)\n",
    "    xs = [20.381729] \n",
    "    \n",
    "    ys = [48.106994] # Donetsk, Ukraine (similar to North Dakota)\n",
    "    xs = [37.714813]\n",
    "   \n",
    "    ys = [41.693297, 36.746417] # Zaragoza, Spain (similar to California) and Malaga, Spain (similar to Florida)\n",
    "    xs = [-0.956810, -4.391810]\n",
    "    \n",
    "    ys = [48.539880, 44.355441] # Baden-Württemberg, Germany and Lot-et-Garonne, France\n",
    "    xs = [8.816138, 0.490569]\n",
    "\n",
    "    ys = [51.810046282775346] #Rothamsted\n",
    "    xs = [-0.356946065871707]\n",
    "    \n",
    "    ys = [39.8197] #CasteloBranco\n",
    "    xs = [7.4965]\n",
    "    \n",
    "    #osmia calibration\n",
    "    ys = [46.4343] #Lusignon\n",
    "    xs = [0.1221]\n",
    "    \n",
    "    #Polish weather for Angelica\n",
    "    ys = [53.18333333,52.65,52.83333333,52.08333333,51.18333333,51.31666667,51.56666667,50.18333333,54.48333333,54.1,53.98333333,53.73333333,53.01666667,53.15,53.21666667,50.46666667,52.16666667,49.66666667,50.18333333,49.56666667,50.26666667,49.88333333,52,52.16666667,50.63333333,52.21666667,51.8,52.16666667,53.03333333,52.81666667,52.08333333,51.35,52.2,51.25,58.38333333,54,53.93333333,52.23333333,50.11666667,49.48333333,53.81666667,53.88333333,53.98333333,51.06666667,50.71666667,50.86666667,51.36666667,51.51666667,53.58333333,51.28333333]    \n",
    "    xs = [17.58333333,18.45,19.25,23.11666667,23.25,22.26666667,23.03333333,17.83333333,17.23333333,18.83333333,18.75,17.03333333,22.76666667,23.03333333,22.11666667,18.48333333,18.56666667,19.16666667,21.48333333,21.68333333,23.1,22.73333333,21.93333333,20.35,19.96666667,17.21666667,18.01666667,18.56666667,16.75,17.3,17.03333333,19.86666667,19.13333333,18.63333333,14.66666667,16,14.83333333,15.58333333,19.98333333,20.13333333,20.66666667,22.46666667,19.53333333,16.91666667,15.96666667,15.68333333,16.95,16.43333333,16.78333333,15.68333333]\n",
    "    \n",
    "    #DK ORGP redo\n",
    "    ys = [11.17566767,11.18535726,8.025830962,8.023522984]\n",
    "    xs = [54.75767469,54.93727718,56.48062701,56.57045574]\n",
    "    \n",
    "    #DK for Ana\n",
    "    ys = [9.65254, 9.29786, 8.63458, 9.31892, 9.74051, 8.68046, 8.83909, 9.99463, 8.99922, 10.571]\n",
    "    xs = [56.7078, 55.2176, 55.5589, 55.8825, 56.1952, 55.7657, 55.9457, 57.2895, 55.1371, 55.2169]\n",
    "\n",
    "    # Bat data\n",
    "    ys = [7.88513,\n",
    "            8.05116,\n",
    "            7.87969,\n",
    "            7.79082,\n",
    "            7.70791,\n",
    "            7.53970,\n",
    "            8.04651,\n",
    "            7.87419,\n",
    "            8.04181,\n",
    "            7.86861,\n",
    "            7.70145,\n",
    "            7.52514,\n",
    "            7.18712,\n",
    "            7.02863,\n",
    "            7.19602,\n",
    "            7.36837,\n",
    "            7.53255,\n",
    "            6.84414,\n",
    "            7.17649,\n",
    "            7.69458,\n",
    "            7.86298,\n",
    "            8.03705,\n",
    "            7.901,\n",
    "            7.43632,\n",
    "            7.0423,\n",
    "            7.70747,\n",
    "            7.571899,\n",
    "            7.573644,\n",
    "            7.601428,\n",
    "            7.77294,\n",
    "            7.7086,\n",
    "            7.68745,\n",
    "            7.553378,\n",
    "            7.657018,\n",
    "            7.599585,\n",
    "            7.68745,\n",
    "            7.575647,\n",
    "            7.683028]\n",
    "    xs = [55.60530,\n",
    "            55.70201,\n",
    "            55.79587,\n",
    "            55.73477,\n",
    "            55.88947,\n",
    "            55.79229,\n",
    "            55.89259,\n",
    "            55.98644,\n",
    "            56.08316,\n",
    "            56.17700,\n",
    "            56.08137,\n",
    "            56.17340,\n",
    "            56.16899,\n",
    "            55.88101,\n",
    "            55.97842,\n",
    "            55.88547,\n",
    "            55.98287,\n",
    "            56.16338,\n",
    "            56.35936,\n",
    "            56.27060,\n",
    "            56.36755,\n",
    "            56.27373,\n",
    "            55.74873335,\n",
    "            56.12676,\n",
    "            55.89034,\n",
    "            55.81821,\n",
    "            55.697319,\n",
    "            55.687427,\n",
    "            55.688484,\n",
    "            55.68251,\n",
    "            55.70688,\n",
    "            55.74106,\n",
    "            55.72575,\n",
    "            55.69058,\n",
    "            55.71823,\n",
    "            55.74106,\n",
    "            55.73732,\n",
    "            55.72136]\n",
    "    \n",
    "    \n",
    "    #names are made using the longtitude and latitude\n",
    "    #names = [str(int(x))+'_'+str(int(y)) for (x, y) in zip(xs, ys)]\n",
    "    names = ['Aarslev', 'Flakkebjerg', 'Foulum', 'Fussingoe', 'Gaardagergaard', 'Harndrup', 'Hesselager', 'Hinnerup', 'Syddjurs', 'Kongskilde_mv', 'Pometet', 'Selleberg', 'Stubberup', 'Ullemose']\n",
    "    names = ['DK_Grantoftegaard_1997']\n",
    "    names = ['TNTU']\n",
    "    names = ['Sweden_1992']\n",
    "    names = ['FI_ID1','FI_ID2','FI_ID3','FI_ID4','FI_ID5','FI_ID6','FI_ID7','FI_ID8','FI_ID9','FI_ID10','FI_ID11','FI_ID12']\n",
    "    names = ['BE_ID1','BE_ID2','BE_ID3','BE_ID4','BE_ID5','BE_ID6','BE_ID7','BE_ID8','BE_ID9','BE_ID10','BE_ID11','BE_ID12']\n",
    "    names = [\"POSB_DK_ID1_2014\", \"POSB_DK_ID2_2014\", \"POSB_DK_ID3_2014\", \"POSB_DK_ID4_2014\"]\n",
    "    names = [\"Forty_E_Vienna\"]\n",
    "    names = [\"Nakhabino_Moscow\"]\n",
    "    names = [\"Witzwil_Bern\"]\n",
    "    names = ['DK_ID21','DK_ID22','DK_ID23','DK_ID24','DK_ID25','DK_ID26','DK_ID27','DK_ID28','DK_ID29','DK_ID30','DK_ID31','DK_ID32','DK_ID33','DK_ID34','DK_ID35','DK_ID36','DK_ID37','DK_ID38','DK_ID39','DK_ID40','DK_ID41','DK_ID42','DK_ID43','DK_ID44','DK_ID45','DK_ID51','DK_ID52','DK_ID53','DK_ID54','DK_ID55','DK_ID56','DK_ID57','DK_ID58','DK_ID59','DK_ID60','DK_ID61','DK_ID62','DK_ID63','DK_ID64','DK_ID65','DK_ID66','DK_ID67','DK_ID68','DK_ID69','DK_ID70','DK_ID71','DK_ID72','DK_ID73','DK_ID74','DK_ID75']\n",
    "    names = [\"Witzwil_Bern\"]\n",
    "    names = [\"DE_Berlin\"]\n",
    "    names = [\"DE_Liblar\"]\n",
    "    names = [\"UK_Norwich_1977\"]\n",
    "    names = [\"US_NorthDakota_2015_2019\",\"US_Oregon_2015_2019\"]\n",
    "    names = [\"SRB_Belgrade_2015_2019\"]\n",
    "    names = [\"UA_Donetsk_2015_2019\"]\n",
    "    names = [\"ES_Zaragoza_2015_2019\",\"ES_Malaga_2015_2019\"]\n",
    "    names = [\"DE_BadenWurttemberg\",\"FR_LotEtGaronne\"]\n",
    "    names = [\"UK_Rothamsted_1959-1960\"]\n",
    "    names = [\"PT_CasteloBranco_2008-2017_hourly\"]\n",
    "    names = [\"FR_Lusignon_1971_hourly\"]\n",
    "    names = [\"PL_plantID_1\",\"PL_plantID_2\",\"PL_plantID_3\",\"PL_plantID_4\",\"PL_plantID_5\",\"PL_plantID_6\",\"PL_plantID_7\",\"PL_plantID_8\",\"PL_plantID_9\",\"PL_plantID_10\",\"PL_plantID_11\",\"PL_plantID_12\",\"PL_plantID_13\",\"PL_plantID_14\",\"PL_plantID_15\",\"PL_plantID_16\",\"PL_plantID_17\",\"PL_plantID_18\",\"PL_plantID_19\",\"PL_plantID_20\",\"PL_plantID_21\",\"PL_plantID_22\",\"PL_plantID_23\",\"PL_plantID_24\",\"PL_plantID_25\",\"PL_plantID_26\",\"PL_plantID_27\",\"PL_plantID_28\",\"PL_plantID_29\",\"PL_plantID30\",\"PL_plantID_31\",\"PL_plantID_32\",\"PL_plantID_33\",\"PL_plantID_34\",\"PL_plantID_35\",\"PL_plantID_36\",\"PL_plantID_37\",\"PL_plantID_38\",\"PL_plantID_39\",\"PL_plantID_40\",\"PL_plantID_41\",\"PL_plantID_42\",\"PL_plantID_43\",\"PL_plantID_44\",\"PL_plantID_45\",\"PL_plantID_46\",\"PL_plantID_47\",\"PL_plantID_48\",\"PL_plantID_49\",\"PL_plantID_50\"]\n",
    "    names = [\"FI_ID1\",\"FI_ID2\",\"FI_ID3\",\"FI_ID4\",\"FI_ID5\",\"FI_ID6\",\"FI_ID7\",\"FI_ID8\",\"FI_ID9\",\"FI_ID10\"]\n",
    "    names = ['DK_ID43','DK_ID44','DK_ID51','DK_ID52']\n",
    "    names = ['LS01', 'LS02', 'LS03', 'LS04', 'LS05', 'LS06', 'LS07', 'LS08', 'LS09', 'LS10']\n",
    "    names = [\"Loc_1\",\n",
    "                \"Loc_2\",\n",
    "                \"Loc_3\",\n",
    "                \"Loc_4\",\n",
    "                \"Loc_5\",\n",
    "                \"Loc_6\",\n",
    "                \"Loc_7\",\n",
    "                \"Loc_8\",\n",
    "                \"Loc_9\",\n",
    "                \"Loc_10\",\n",
    "                \"Loc_11\",\n",
    "                \"Loc_12\",\n",
    "                \"Loc_13\",\n",
    "                \"Loc_14\",\n",
    "                \"Loc_15\",\n",
    "                \"Loc_16\",\n",
    "                \"Loc_17\",\n",
    "                \"Loc_18\",\n",
    "                \"Loc_19\",\n",
    "                \"Loc_20\",\n",
    "                \"Loc_21\",\n",
    "                \"Loc_22\",\n",
    "                \"Loc_23\",\n",
    "                \"Loc_24\",\n",
    "                \"Loc_25\",\n",
    "                \"Loc_26\",\n",
    "                \"Loc_27\",\n",
    "                \"Loc_28\",\n",
    "                \"Loc_29\",\n",
    "                \"Loc_30\",\n",
    "                \"Loc_31\",\n",
    "                \"Loc_32\",\n",
    "                \"Loc_33\",\n",
    "                \"Loc_34\",\n",
    "                \"Loc_35\",\n",
    "                \"Loc_36\",\n",
    "                \"Loc_37\",\n",
    "                \"Loc_38\"]\n",
    "    \n",
    "    print(\"Number of names: \",len(names))\n",
    "    print(\"Number of xs: \",len(xs))\n",
    "    print(\"Number of ys: \",len(ys))\n",
    "    return startyear, endyear, xs, ys, names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of names:  38\n",
      "Number of xs:  38\n",
      "Number of ys:  38\n",
      "reading era5_temp_2023_01.grib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_117454/560294453.py:41: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  outdf[count]=pd.concat([outdf[count], out], axis=0, ignore_index=True)\n",
      "/tmp/ipykernel_117454/560294453.py:41: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  outdf[count]=pd.concat([outdf[count], out], axis=0, ignore_index=True)\n",
      "/tmp/ipykernel_117454/560294453.py:41: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  outdf[count]=pd.concat([outdf[count], out], axis=0, ignore_index=True)\n",
      "/tmp/ipykernel_117454/560294453.py:41: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  outdf[count]=pd.concat([outdf[count], out], axis=0, ignore_index=True)\n",
      "/tmp/ipykernel_117454/560294453.py:41: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  outdf[count]=pd.concat([outdf[count], out], axis=0, ignore_index=True)\n",
      "/tmp/ipykernel_117454/560294453.py:41: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  outdf[count]=pd.concat([outdf[count], out], axis=0, ignore_index=True)\n",
      "/tmp/ipykernel_117454/560294453.py:41: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  outdf[count]=pd.concat([outdf[count], out], axis=0, ignore_index=True)\n",
      "/tmp/ipykernel_117454/560294453.py:41: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  outdf[count]=pd.concat([outdf[count], out], axis=0, ignore_index=True)\n",
      "/tmp/ipykernel_117454/560294453.py:41: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  outdf[count]=pd.concat([outdf[count], out], axis=0, ignore_index=True)\n",
      "/tmp/ipykernel_117454/560294453.py:41: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  outdf[count]=pd.concat([outdf[count], out], axis=0, ignore_index=True)\n",
      "/tmp/ipykernel_117454/560294453.py:41: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  outdf[count]=pd.concat([outdf[count], out], axis=0, ignore_index=True)\n",
      "/tmp/ipykernel_117454/560294453.py:41: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  outdf[count]=pd.concat([outdf[count], out], axis=0, ignore_index=True)\n",
      "/tmp/ipykernel_117454/560294453.py:41: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  outdf[count]=pd.concat([outdf[count], out], axis=0, ignore_index=True)\n",
      "/tmp/ipykernel_117454/560294453.py:41: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  outdf[count]=pd.concat([outdf[count], out], axis=0, ignore_index=True)\n",
      "/tmp/ipykernel_117454/560294453.py:41: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  outdf[count]=pd.concat([outdf[count], out], axis=0, ignore_index=True)\n",
      "/tmp/ipykernel_117454/560294453.py:41: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  outdf[count]=pd.concat([outdf[count], out], axis=0, ignore_index=True)\n",
      "/tmp/ipykernel_117454/560294453.py:41: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  outdf[count]=pd.concat([outdf[count], out], axis=0, ignore_index=True)\n",
      "/tmp/ipykernel_117454/560294453.py:41: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  outdf[count]=pd.concat([outdf[count], out], axis=0, ignore_index=True)\n",
      "/tmp/ipykernel_117454/560294453.py:41: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  outdf[count]=pd.concat([outdf[count], out], axis=0, ignore_index=True)\n",
      "/tmp/ipykernel_117454/560294453.py:41: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  outdf[count]=pd.concat([outdf[count], out], axis=0, ignore_index=True)\n",
      "/tmp/ipykernel_117454/560294453.py:41: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  outdf[count]=pd.concat([outdf[count], out], axis=0, ignore_index=True)\n",
      "/tmp/ipykernel_117454/560294453.py:41: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  outdf[count]=pd.concat([outdf[count], out], axis=0, ignore_index=True)\n",
      "/tmp/ipykernel_117454/560294453.py:41: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  outdf[count]=pd.concat([outdf[count], out], axis=0, ignore_index=True)\n",
      "/tmp/ipykernel_117454/560294453.py:41: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  outdf[count]=pd.concat([outdf[count], out], axis=0, ignore_index=True)\n",
      "/tmp/ipykernel_117454/560294453.py:41: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  outdf[count]=pd.concat([outdf[count], out], axis=0, ignore_index=True)\n",
      "/tmp/ipykernel_117454/560294453.py:41: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  outdf[count]=pd.concat([outdf[count], out], axis=0, ignore_index=True)\n",
      "/tmp/ipykernel_117454/560294453.py:41: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  outdf[count]=pd.concat([outdf[count], out], axis=0, ignore_index=True)\n",
      "/tmp/ipykernel_117454/560294453.py:41: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  outdf[count]=pd.concat([outdf[count], out], axis=0, ignore_index=True)\n",
      "/tmp/ipykernel_117454/560294453.py:41: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  outdf[count]=pd.concat([outdf[count], out], axis=0, ignore_index=True)\n",
      "/tmp/ipykernel_117454/560294453.py:41: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  outdf[count]=pd.concat([outdf[count], out], axis=0, ignore_index=True)\n",
      "/tmp/ipykernel_117454/560294453.py:41: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  outdf[count]=pd.concat([outdf[count], out], axis=0, ignore_index=True)\n",
      "/tmp/ipykernel_117454/560294453.py:41: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  outdf[count]=pd.concat([outdf[count], out], axis=0, ignore_index=True)\n",
      "/tmp/ipykernel_117454/560294453.py:41: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  outdf[count]=pd.concat([outdf[count], out], axis=0, ignore_index=True)\n",
      "/tmp/ipykernel_117454/560294453.py:41: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  outdf[count]=pd.concat([outdf[count], out], axis=0, ignore_index=True)\n",
      "/tmp/ipykernel_117454/560294453.py:41: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  outdf[count]=pd.concat([outdf[count], out], axis=0, ignore_index=True)\n",
      "/tmp/ipykernel_117454/560294453.py:41: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  outdf[count]=pd.concat([outdf[count], out], axis=0, ignore_index=True)\n",
      "/tmp/ipykernel_117454/560294453.py:41: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  outdf[count]=pd.concat([outdf[count], out], axis=0, ignore_index=True)\n",
      "/tmp/ipykernel_117454/560294453.py:41: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  outdf[count]=pd.concat([outdf[count], out], axis=0, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading era5_temp_2023_02.grib\n",
      "reading era5_temp_2023_03.grib\n",
      "reading era5_temp_2023_04.grib\n",
      "reading era5_temp_2023_05.grib\n",
      "reading era5_temp_2023_06.grib\n",
      "reading era5_temp_2023_07.grib\n",
      "reading era5_temp_2023_08.grib\n",
      "reading era5_temp_2023_09.grib\n",
      "reading era5_temp_2023_10.grib\n",
      "reading era5_temp_2023_11.grib\n",
      "reading era5_temp_2023_12.grib\n",
      "reading era5_temp_2024_01.grib\n",
      "reading era5_temp_2024_02.grib\n",
      "reading era5_temp_2024_03.grib\n",
      "reading era5_temp_2024_04.grib\n",
      "reading era5_temp_2024_05.grib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Can't create file '/home/au472091/OneDrive/au/projects/pam_bats/analysis/data/weather/temp/era5_temp_2024_07.grib.9093e.idx'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/au472091/.local/lib/python3.10/site-packages/cfgrib/messages.py\", line 535, in from_indexpath_or_filestream\n",
      "    self = cls.from_fieldset(filestream, index_keys, computed_keys)\n",
      "  File \"/home/au472091/.local/lib/python3.10/site-packages/cfgrib/messages.py\", line 378, in from_fieldset\n",
      "    return cls.from_fieldset_and_iteritems(fieldset, iteritems, index_keys, computed_keys)\n",
      "  File \"/home/au472091/.local/lib/python3.10/site-packages/cfgrib/messages.py\", line 391, in from_fieldset_and_iteritems\n",
      "    for field_id, raw_field in iteritems:\n",
      "  File \"/home/au472091/.local/lib/python3.10/site-packages/cfgrib/messages.py\", line 291, in __iter__\n",
      "    for message in self.itervalues():\n",
      "  File \"/home/au472091/.local/lib/python3.10/site-packages/cfgrib/messages.py\", line 267, in itervalues\n",
      "    with open(self.filestream.path, \"rb\") as file:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/home/au472091/OneDrive/au/projects/pam_bats/analysis/data/weather/temp/era5_temp_2024_07.grib'\n",
      "Can't read index file '/home/au472091/OneDrive/au/projects/pam_bats/analysis/data/weather/temp/era5_temp_2024_07.grib.9093e.idx'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/au472091/.local/lib/python3.10/site-packages/cfgrib/messages.py\", line 544, in from_indexpath_or_filestream\n",
      "    index_mtime = os.path.getmtime(indexpath)\n",
      "  File \"/usr/lib/python3.10/genericpath.py\", line 55, in getmtime\n",
      "    return os.stat(filename).st_mtime\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/home/au472091/OneDrive/au/projects/pam_bats/analysis/data/weather/temp/era5_temp_2024_07.grib.9093e.idx'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading era5_temp_2024_06.grib\n",
      "reading era5_temp_2024_07.grib\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/au472091/OneDrive/au/projects/pam_bats/analysis/data/weather/temp/era5_temp_2024_07.grib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 55\u001b[0m\n\u001b[1;32m     51\u001b[0m actual_df \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m#loading the data\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m#temperature, in K, minus Kelvin\u001b[39;00m\n\u001b[0;32m---> 55\u001b[0m temp \u001b[38;5;241m=\u001b[39m \u001b[43mget_param_era5\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdir_temp_era5\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuffix_temp_era5\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstartyear\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendyear\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmean_temp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhourly_flag\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(xs)):\n\u001b[1;32m     57\u001b[0m     temp[i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_temp\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m Kelvin\n",
      "Cell \u001b[0;32mIn[8], line 12\u001b[0m, in \u001b[0;36mget_param_era5\u001b[0;34m(filepath, suffix, lat, long, yearfrom, yearto, paramname, hourly_flag)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m month \u001b[38;5;129;01min\u001b[39;00m existing_months_era5:\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreading \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m suffix\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(year)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mmonth\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.grib\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m     ds \u001b[38;5;241m=\u001b[39m \u001b[43mxr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuffix\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43myear\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mmonth\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.grib\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcfgrib\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlatitude\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlongitude\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtime\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstep\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m#ds = ds.interpolate_na()\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     data_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m (ds\u001b[38;5;241m.\u001b[39mkeys())[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/xarray/backends/api.py:277\u001b[0m, in \u001b[0;36mload_dataset\u001b[0;34m(filename_or_obj, **kwargs)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcache\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcache has no effect in this context\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 277\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mopen_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m ds:\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ds\u001b[38;5;241m.\u001b[39mload()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/xarray/backends/api.py:571\u001b[0m, in \u001b[0;36mopen_dataset\u001b[0;34m(filename_or_obj, engine, chunks, cache, decode_cf, mask_and_scale, decode_times, decode_timedelta, use_cftime, concat_characters, decode_coords, drop_variables, inline_array, chunked_array_type, from_array_kwargs, backend_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    559\u001b[0m decoders \u001b[38;5;241m=\u001b[39m _resolve_decoders_kwargs(\n\u001b[1;32m    560\u001b[0m     decode_cf,\n\u001b[1;32m    561\u001b[0m     open_backend_dataset_parameters\u001b[38;5;241m=\u001b[39mbackend\u001b[38;5;241m.\u001b[39mopen_dataset_parameters,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    567\u001b[0m     decode_coords\u001b[38;5;241m=\u001b[39mdecode_coords,\n\u001b[1;32m    568\u001b[0m )\n\u001b[1;32m    570\u001b[0m overwrite_encoded_chunks \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverwrite_encoded_chunks\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 571\u001b[0m backend_ds \u001b[38;5;241m=\u001b[39m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    572\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    573\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdrop_variables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop_variables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    574\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdecoders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    575\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    576\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    577\u001b[0m ds \u001b[38;5;241m=\u001b[39m _dataset_from_backend_dataset(\n\u001b[1;32m    578\u001b[0m     backend_ds,\n\u001b[1;32m    579\u001b[0m     filename_or_obj,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    589\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    590\u001b[0m )\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ds\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/cfgrib/xarray_plugin.py:109\u001b[0m, in \u001b[0;36mCfGribBackend.open_dataset\u001b[0;34m(self, filename_or_obj, mask_and_scale, decode_times, concat_characters, decode_coords, drop_variables, use_cftime, decode_timedelta, lock, indexpath, filter_by_keys, read_keys, encode_cf, squeeze, time_dims, errors, extra_coords, cache_geo_coords)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mopen_dataset\u001b[39m(\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     89\u001b[0m     filename_or_obj: T\u001b[38;5;241m.\u001b[39mUnion[\u001b[38;5;28mstr\u001b[39m, abc\u001b[38;5;241m.\u001b[39mMappingFieldset[T\u001b[38;5;241m.\u001b[39mAny, abc\u001b[38;5;241m.\u001b[39mField]],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    107\u001b[0m     cache_geo_coords: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    108\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m xr\u001b[38;5;241m.\u001b[39mDataset:\n\u001b[0;32m--> 109\u001b[0m     store \u001b[38;5;241m=\u001b[39m \u001b[43mCfGribDataStore\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindexpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindexpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilter_by_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilter_by_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m        \u001b[49m\u001b[43mread_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencode_cf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_cf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m        \u001b[49m\u001b[43msqueeze\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtime_dims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_dims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_coords\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_coords\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_geo_coords\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_geo_coords\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m xr\u001b[38;5;241m.\u001b[39mcore\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclose_on_error(store):\n\u001b[1;32m    123\u001b[0m         \u001b[38;5;28mvars\u001b[39m, attrs \u001b[38;5;241m=\u001b[39m store\u001b[38;5;241m.\u001b[39mload()  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/cfgrib/xarray_plugin.py:40\u001b[0m, in \u001b[0;36mCfGribDataStore.__init__\u001b[0;34m(self, filename, lock, **backend_kwargs)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     39\u001b[0m     opener \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mopen_fieldset\n\u001b[0;32m---> 40\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mds \u001b[38;5;241m=\u001b[39m \u001b[43mopener\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbackend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/cfgrib/dataset.py:798\u001b[0m, in \u001b[0;36mopen_file\u001b[0;34m(path, errors, indexpath, filter_by_keys, read_keys, time_dims, extra_coords, **kwargs)\u001b[0m\n\u001b[1;32m    796\u001b[0m stream \u001b[38;5;241m=\u001b[39m messages\u001b[38;5;241m.\u001b[39mFileStream(path, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m    797\u001b[0m index_keys \u001b[38;5;241m=\u001b[39m compute_index_keys(time_dims, extra_coords)\n\u001b[0;32m--> 798\u001b[0m index \u001b[38;5;241m=\u001b[39m \u001b[43mopen_fileindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilter_by_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilter_by_keys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m open_from_index(index, read_keys, time_dims, extra_coords, errors\u001b[38;5;241m=\u001b[39merrors, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/cfgrib/dataset.py:778\u001b[0m, in \u001b[0;36mopen_fileindex\u001b[0;34m(stream, indexpath, index_keys, filter_by_keys, computed_keys)\u001b[0m\n\u001b[1;32m    770\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mopen_fileindex\u001b[39m(\n\u001b[1;32m    771\u001b[0m     stream: messages\u001b[38;5;241m.\u001b[39mFileStream,\n\u001b[1;32m    772\u001b[0m     indexpath: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m messages\u001b[38;5;241m.\u001b[39mDEFAULT_INDEXPATH,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    775\u001b[0m     computed_keys: messages\u001b[38;5;241m.\u001b[39mComputedKeysType \u001b[38;5;241m=\u001b[39m cfmessage\u001b[38;5;241m.\u001b[39mCOMPUTED_KEYS,\n\u001b[1;32m    776\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m messages\u001b[38;5;241m.\u001b[39mFileIndex:\n\u001b[1;32m    777\u001b[0m     index_keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28mset\u001b[39m(index_keys) \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mset\u001b[39m(filter_by_keys))\n\u001b[0;32m--> 778\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[43mmessages\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFileIndex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_indexpath_or_filestream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    779\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindexpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomputed_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomputed_keys\u001b[49m\n\u001b[1;32m    780\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    781\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m index\u001b[38;5;241m.\u001b[39msubindex(filter_by_keys)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/cfgrib/messages.py:561\u001b[0m, in \u001b[0;36mFileIndex.from_indexpath_or_filestream\u001b[0;34m(cls, filestream, index_keys, indexpath, computed_keys, log)\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    559\u001b[0m     log\u001b[38;5;241m.\u001b[39mexception(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt read index file \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, indexpath)\n\u001b[0;32m--> 561\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_fieldset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilestream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomputed_keys\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/cfgrib/messages.py:378\u001b[0m, in \u001b[0;36mFieldsetIndex.from_fieldset\u001b[0;34m(cls, fieldset, index_keys, computed_keys)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    377\u001b[0m     iteritems \u001b[38;5;241m=\u001b[39m \u001b[38;5;28menumerate\u001b[39m(fieldset)\n\u001b[0;32m--> 378\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_fieldset_and_iteritems\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfieldset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miteritems\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomputed_keys\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/cfgrib/messages.py:391\u001b[0m, in \u001b[0;36mFieldsetIndex.from_fieldset_and_iteritems\u001b[0;34m(cls, fieldset, iteritems, index_keys, computed_keys)\u001b[0m\n\u001b[1;32m    389\u001b[0m index_keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(index_keys)\n\u001b[1;32m    390\u001b[0m header_values_cache \u001b[38;5;241m=\u001b[39m {}  \u001b[38;5;66;03m# type: T.Dict[T.Tuple[T.Any, type], T.Any]\u001b[39;00m\n\u001b[0;32m--> 391\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m field_id, raw_field \u001b[38;5;129;01min\u001b[39;00m iteritems:\n\u001b[1;32m    392\u001b[0m     field \u001b[38;5;241m=\u001b[39m ComputedKeysAdapter(raw_field, computed_keys)\n\u001b[1;32m    393\u001b[0m     header_values \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/cfgrib/messages.py:291\u001b[0m, in \u001b[0;36mFileStreamItems.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    289\u001b[0m old_offset \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    290\u001b[0m count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 291\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m message \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitervalues():\n\u001b[1;32m    292\u001b[0m     offset \u001b[38;5;241m=\u001b[39m message\u001b[38;5;241m.\u001b[39mmessage_get(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moffset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m offset \u001b[38;5;241m==\u001b[39m old_offset:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/cfgrib/messages.py:267\u001b[0m, in \u001b[0;36mFileStreamItems.itervalues\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mitervalues\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T\u001b[38;5;241m.\u001b[39mIterator[Message]:\n\u001b[1;32m    266\u001b[0m     errors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilestream\u001b[38;5;241m.\u001b[39merrors\n\u001b[0;32m--> 267\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilestream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m    268\u001b[0m         \u001b[38;5;66;03m# enable MULTI-FIELD support on sequential reads (like when building the index)\u001b[39;00m\n\u001b[1;32m    269\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m multi_enabled(file):\n\u001b[1;32m    270\u001b[0m             valid_message_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/au472091/OneDrive/au/projects/pam_bats/analysis/data/weather/temp/era5_temp_2024_07.grib'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "Kelvin = 273.15\n",
    "\n",
    "#source file paths\n",
    "dir_soiltemp_era5 = '/work/weather/era5monthly/soiltemp/'\n",
    "dir_snow_cover_era5 = '/work/weather/era5monthly/snowdepth/'\n",
    "dir_precip_era5 =  '/home/au472091/OneDrive/au/projects/pam_bats/analysis/data/weather/precip/'\n",
    "dir_temp_era5 = '/home/au472091/OneDrive/au/projects/pam_bats/analysis/data/weather/temp'\n",
    "dir_dewpointtemp_era5 = '/work/weather/era5monthly/dewpointtemp/'\n",
    "dir_radiation_era5 = '/work/weather/era5monthly/radiation/'\n",
    "dir_windu_era5 = '/home/au472091/OneDrive/au/projects/pam_bats/analysis/data/weather/windu/'\n",
    "dir_windv_era5 = '/home/au472091/OneDrive/au/projects/pam_bats/analysis/data/weather/windv/'\n",
    "#the following two are for Morten's bat project\n",
    "dir_totalcloudcover_era5 = '/work/weather/era5monthly/totalcloudcover/'\n",
    "dir_cloudbaseheight_era5 = '/work/weather/era5monthly/cloudbaseheight/'\n",
    "\n",
    "suffix_soiltemp_era5 = 'era5_soiltemp'\n",
    "suffix_snowdepth_era5 = 'era5_snowdepth'\n",
    "suffix_precip_era5 = 'era5_precip'\n",
    "suffix_dewpointtemp_era5 = 'era5_dewpointtemp'\n",
    "suffix_temp_era5 = 'era5_temp'\n",
    "suffix_radiation_era5 = 'era5_radiation'\n",
    "suffix_windu_era5 = 'era5_windu'\n",
    "suffix_windv_era5 = 'era5_windv'\n",
    "#the following two are for Morten's bat project\n",
    "suffix_totalcloudcover_era5 ='era5_total_cloud_cover'\n",
    "suffix_cloudbaseheight_era5 ='era5_cloud_base_height'\n",
    "\n",
    "output_dir = '/home/au472091/OneDrive/au/projects/pam_bats/analysis/data/weather/generated_data'\n",
    "\n",
    "startyear, endyear, xs, ys, names = country_name_coordinate_year()\n",
    "\n",
    "#starting year and ending year\n",
    "#startyear = 2013\n",
    "#endyear = 2022\n",
    "\n",
    "#latitude and longtiude, cournty code\n",
    "#xs=[10.44519, 11.38064, 9.56189, 9.85922, 11.32218, 10.04418, 10.78797, 10.10535, 10.49498, 11.54320, 12.31061, 10.54788, 11.63675, 10.74685]#[0.3561]\n",
    "#ys=[55.31168, 55.32943, 56.49385, 56.48013, 55.38351, 55.47229, 55.21177, 56.24818, 56.30509, 55.38482, 55.67096, 55.39099, 55.28202, 55.11464]#[51.8094] lat\n",
    "#ys = [56.0803]\n",
    "#xs = [10.1353]\n",
    "#countries=['DK']\n",
    "\n",
    "#change this to true if hourly data is needed\n",
    "hourly_flag = True\n",
    "\n",
    "#names are made using the longtitude and latitude\n",
    "#names = [str(int(x))+'_'+str(int(y)) for (x, y) in zip(xs, ys)]\n",
    "#names = ['Aarslev', 'Flakkebjerg', 'Foulum', 'Fussingoe', 'Gaardagergaard', 'Harndrup', 'Hesselager', 'Hinnerup', 'Syddjurs', 'Kongskilde_mv', 'Pometet', 'Selleberg', 'Stubberup', 'Ullemose']\n",
    "#names = ['Aarhus']\n",
    "#variable to store the loaded data\n",
    "actual_df = []\n",
    "#loading the data\n",
    "\n",
    "#temperature, in K, minus Kelvin\n",
    "temp = get_param_era5(dir_temp_era5, suffix_temp_era5, ys, xs, startyear, endyear, 'mean_temp', hourly_flag)\n",
    "for i in range(len(xs)):\n",
    "    temp[i]['mean_temp'] -= Kelvin\n",
    "    temp[i]['mean_temp'] = temp[i]['mean_temp'].fillna(-99999)\n",
    "    actual_df.append(temp[i])\n",
    "    actual_df[i].insert(0, \"year\", actual_df[i].apply(lambda row: row['time'].year, axis=1), True)\n",
    "    actual_df[i].insert(0, \"month\", actual_df[i].apply(lambda row: row['time'].month, axis=1), True)\n",
    "    actual_df[i].insert(0, \"day\", actual_df[i].apply(lambda row: row['time'].day, axis=1), True)\n",
    "    actual_df[i].insert(0, \"hour\", actual_df[i].apply(lambda row: row['time'].hour, axis=1), True)\n",
    "\n",
    "#wind, u: direction of east; v: direction of north, based on these two, the wind is converted into wind speed and direction (from 0 to 2pi, staring from east and anticlockwise)\n",
    "wind_u = get_param_era5(dir_windu_era5, suffix_windu_era5, ys, xs, startyear, endyear, 'wind_u', hourly_flag)\n",
    "wind_v = get_param_era5(dir_windv_era5, suffix_windv_era5, ys, xs, startyear, endyear, 'wind_v', hourly_flag)\n",
    "wind_speed = []\n",
    "wind_direction = []\n",
    "for i in range(len(xs)):\n",
    "    wind_speed.append(wind_u[i].copy(deep=True))\n",
    "    wind_speed[i].rename(columns={'wind_u':'wind_speed'}, inplace=True)\n",
    "    wind_direction.append(wind_u[i].copy(deep=True))\n",
    "    wind_direction[i].rename(columns={'wind_u':'wind_direction'}, inplace=True)\n",
    "    wind_speed[i]['wind_speed'] = np.sqrt(np.power(wind_v[i]['wind_v'],2)+np.power(wind_u[i]['wind_u'],2))\n",
    "    wind_direction[i]['wind_direction'] = np.arctan2(wind_v[i]['wind_v'], wind_u[i]['wind_u']) #east is the 0\n",
    "    wind_direction[i].loc[wind_direction[i]['wind_direction']<0, 'wind_direction'] += 2*np.pi\n",
    "    #wind_speed[i]['wind_speed'] = wind_speed[i]['wind_speed'].fillna(-99999)\n",
    "    #wind_direction[i]['wind_direction'] = wind_direction[i]['wind_direction'].fillna(-99999)\n",
    "    actual_df[i].insert(6, 'wind_speed', wind_speed[i]['wind_speed'], True)\n",
    "    actual_df[i].insert(7, 'wind_direction', wind_direction[i]['wind_direction'], True)\n",
    "\n",
    "\n",
    "#precipitation\n",
    "precip = get_param_era5(dir_precip_era5, suffix_precip_era5, ys, xs, startyear, endyear, 'precip', hourly_flag)\n",
    "for i in range(len(xs)):\n",
    "    precip[i]['precip'] *= 1000 #change to mm\n",
    "    precip[i].loc[precip[i]['precip']<0.0001, 'precip']=0.0\n",
    "    #precip[i]['precip'] = precip[i]['precip'].fillna(-99999)\n",
    "    actual_df[i].insert(8, 'precip', precip[i]['precip'], True)\n",
    "\n",
    "# #soil Temperature\n",
    "# soiltemp = get_param_era5(dir_soiltemp_era5, suffix_soiltemp_era5, ys, xs, startyear, endyear, 'soiltemp', hourly_flag)\n",
    "# for i in range(len(xs)):\n",
    "#     soiltemp[i]['soiltemp'] -= Kelvin\n",
    "#     #soiltemp[i]['soiltemp'] = soiltemp[i]['soiltemp'].fillna(-99999)\n",
    "#     actual_df[i].insert(9, 'soiltemp', soiltemp[i]['soiltemp'], True)\n",
    "\n",
    "# #snow depth\n",
    "# snowdepth = get_param_era5(dir_snow_cover_era5, suffix_snowdepth_era5, ys, xs, startyear, endyear, 'snowdepth', hourly_flag)\n",
    "# for i in range(len(xs)):\n",
    "#     snowdepth[i].loc[snowdepth[i]['snowdepth']<0, 'snowdepth'] = 0\n",
    "#     snowdepth[i]['snowdepth'] *= 1000 #change to mm\n",
    "#     #snowdepth[i]['snowdepth'] = snowdepth[i]['snowdepth'].fillna(-99999)\n",
    "#     actual_df[i].insert(10, 'snowdepth', snowdepth[i]['snowdepth'], True)\n",
    "\n",
    "# #humidity\n",
    "# dewtemp = get_param_era5(dir_dewpointtemp_era5, suffix_dewpointtemp_era5, ys, xs, startyear, endyear, 'dewtemp', hourly_flag)\n",
    "# humidity = []\n",
    "# for i in range(len(xs)):\n",
    "#     humidity.append(dewtemp[i].copy(deep=True))\n",
    "#     humidity[i].rename(columns={'dewtemp':'humidity'}, inplace=True)\n",
    "#     dewtemp[i]['dewtemp'] -= Kelvin\n",
    "#     humidity[i]['humidity'] = 100 - 5*(temp[i]['mean_temp']-dewtemp[i]['dewtemp'])\n",
    "#     #humidity[i]['humidity'] = humidity[i]['humidity'].fillna(-99999)\n",
    "#     actual_df[i].insert(11, 'humidity', humidity[i]['humidity'], True)\n",
    "\n",
    "# #radiation\n",
    "# radiation = get_param_era5(dir_radiation_era5, suffix_radiation_era5, ys, xs, startyear, endyear, 'radiation', hourly_flag)\n",
    "# for i in range(len(xs)):\n",
    "#     radiation[i].loc[radiation[i]['radiation']<0.01, 'radiation']=0.0\n",
    "#     #radiation[i]['radiation'] /= 3600.0\n",
    "#     #radiation[i]['radiation'] = radiation[i]['radiation'].fillna(-99999)\n",
    "#     actual_df[i].insert(12, 'radiation', radiation[i]['radiation'], True)\n",
    "\n",
    "\n",
    "# #the following two are for Morten's bat project, please comment them out\n",
    "# #cloudbaseheight\n",
    "# \"\"\"\n",
    "# cloudbaseheight = get_param_era5(dir_cloudbaseheight_era5, suffix_cloudbaseheight_era5, ys, xs, startyear, endyear, 'cloudbaseheight', hourly_flag)\n",
    "# for i in range(len(xs)):\n",
    "#     #cloudbaseheight[i]['cloudbaseheight'] = cloudbaseheight[i]['cloudbaseheight'].fillna(-99999)    \n",
    "#     actual_df[i].insert(9, 'cloudbaseheight', cloudbaseheight[i]['cloudbaseheight'], True)\n",
    "# totalcloudcover = get_param_era5(dir_totalcloudcover_era5, suffix_totalcloudcover_era5, ys, xs, startyear, endyear, 'totalcloudcover', hourly_flag)\n",
    "# for i in range(len(xs)):\n",
    "#     #totalcloudcover[i]['totalcloudcover'] = totalcloudcover[i]['totalcloudcover'].fillna(-99999)\n",
    "#     actual_df[i].insert(10, 'totalcloudcover', totalcloudcover[i]['totalcloudcover'], True)\n",
    "# \"\"\"\n",
    "#processing the data.\n",
    "for i in range(len(xs)):\n",
    "    actual_df[i].drop('time', axis=1, inplace=True) # let us drop the time column before interpolating\n",
    "    \n",
    "\n",
    "    print(\"Looking for weather @ coordinates Lat: \"+str(ys[i])+\" Long: \"+str(xs[i]))\n",
    "    #actual_df[i]['SoilTemp']=actual_df[i]['SoilTemp']-Kelvin\n",
    "    #actual_df[i]['SnowCover']=actual_df[i]['SnowCover']*100 #originally in m\n",
    "    interpolated_data = interpolate_data(actual_df[i])\n",
    "    write_weather(interpolated_data, os.path.join(output_dir, str(names[i])+\"_era5.pre\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
